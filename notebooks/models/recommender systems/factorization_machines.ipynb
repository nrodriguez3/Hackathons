{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastFM\n",
    "from fastFM.datasets import make_user_item_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastFM import sgd\n",
    "from fastFM import als\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csc_matrix\n",
    "from fastFM import mcmc\n",
    "import functools as fct\n",
    "import itertools as itools\n",
    "import random, scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of fastFM\n",
    "https://github.com/ibayer/fastFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization Machine\n",
    "\n",
    "There are two key advantages with this method:\n",
    "- Linear complexity in learning the interaction between feature vectors\n",
    "- Able to deal with sparse datasets\n",
    "\n",
    "### Intuition:\n",
    "Say we want to predict the rating $r_{u, i}$ (Rating for user $u$ and $i$) using SVDFunk, we would do:\n",
    "\\begin{equation}\n",
    "    r_{u, i} = b_{u, i} + p^T_u q_i\n",
    "\\end{equation}\n",
    "\n",
    "where $P \\in \\mathbb{R}^{|U| \\times l}$ and $Q \\in \\mathbb{R}^{|I| \\times l}$ are the learnt low-rank matrices with $l$ latent features and $b_{u, i}$ is the bias. Here we see that the feature (i.e., each component of the vectors $p_u$ and $q_i$) related to $u$ and $i$ are interacting with each other explicitly. FM models this interaction using a feature vector for each feature.\n",
    "\n",
    "This means we can first have:\n",
    "\\begin{equation}\n",
    "    \\hat{y}(\\textbf{x}) = w_0 + \\sum^n_{i = 1} w_i x_i\n",
    "\\end{equation}\n",
    "where $w_0$ is the bias, the $\\textbf{x} \\in \\mathbb{R}^{1 \\times n}$ is a feature vector for user $u$ to predict rating for item $i$ and $w_i$ is the weight assigned to each feature $x_i$. We note that this is the linear regression formula. But we have left out the interactions between features!\n",
    "\n",
    "Therefore, we add the interactions between pairs of features as such:\n",
    "\\begin{equation}\n",
    "    \\hat{y}(\\textbf{x}) = w_0 + \\sum^n_{i = 1} w_i x_i + \\sum^n_{i = 1} \\sum^j_{j = i + 1} w_{i, j} x_i x_j\n",
    "\\end{equation}\n",
    "for the interaction between the features $x_i$ and $x_j$, we assign a weight $w_{i, j}$. \n",
    "\n",
    "There's two problems with the above:\n",
    "1. Under a sparse dataset, there's little observed interactions between features $x_i$ and $x_j$, so the weight $w_{i, j}$ is difficult to learn.\n",
    "2. This model is expensive! It has a complexity of $\\mathcal{O}(n^2)$. \n",
    "\n",
    "### Idea\n",
    "Same as the idea of matrix factorization of the user-item matrix with high sparsity, we factorize the feature interaction weight matrix $\\mathbf{W} \\in \\mathbb{R}^{n \\times n}$ to $\\mathbf{V} \\in \\mathbb{R}^{n \\times k}$. Therefore, we are now estimating the weights for feature interactions: $\\hat{w}_{i, j} = \\langle \\mathbb{v}_i, \\mathbb{v}_j \\rangle$. $\\langle \\cdot, \\cdot \\rangle$ is the dot product between two vectors. \n",
    "\n",
    "This gives the FM model equation:\n",
    "\\begin{equation}\n",
    "    \\hat{y}(\\textbf{x}) = w_0 + \\sum^n_{i = 1} w_i x_i + \\sum^n_{i = 1} \\sum^n_{j = i + 1} \\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j\n",
    "\\end{equation}\n",
    "where the model parameters that have to be estimated are:\n",
    "\\begin{equation}\n",
    "    w_0 \\in \\mathbb{R}, \\textbf{w} \\in \\mathbb{R}^n, \\textbf{V} \\in \\mathbb{R}^{n \\times k}\n",
    "\\end{equation}\n",
    "Once again $w_0$ is the bias, $\\textbf{w}$ are the weights for each feature and $\\textbf{V}$ are the vectors to estimate the weights to be assigned to the interactions between features. $k \\in \\mathbb{R}^+$ is a hyperparameter (a parameter to parametize other parameters) to define the dimensionality of the factorization. Obviously, we want $k < n$.\n",
    "\n",
    "We need to show that we can in fact factorize the weight matrix $\\mathbf{W}$. We know that we can since it is a positive definite matrix (because it's symmetrical and all the pivots are positive).\n",
    "\n",
    "## However, what's so great about the FM model??\n",
    "We see that the complexity is $\\mathcal{O}(kn^2)$. Here comes the magic, we show that it can be computed in linear time $\\mathcal{O}(kn)$. We first note that we only need to simplify the third term: \n",
    "\\begin{equation}\n",
    "    \\sum^n_{i = 1} \\sum^n_{j = i + 1} \\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j\n",
    "\\end{equation}\n",
    "\n",
    "### Lemma 3.1 (clarified from FM paper)\n",
    "\\begin{equation}\n",
    "    \\sum^n_{i = 1} \\sum^n_{j = i + 1} \\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j = \\frac{1}{2} \\sum^k_{f = 1}((\\sum^n_{i = 1} v_{i, f} x_i)^2 - \\sum^n_{i = 1} v^2_{i, f} x^2_i)\n",
    "\\end{equation}\n",
    "\n",
    "Ignore $\\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j$, and think about a $n \\times n$ square for $\\sum^n_{i = 1} \\sum^n_{j = 1}$ and that $\\sum^n_{i = 1} \\sum^n_{j = i + 1}$ is actually the upper or lower triangles. Upper and lower triangles are the same since dot product is commutative, i.e., $\\langle \\textbf{v}_i, \\textbf{v}_j \\rangle = \\langle \\textbf{v}_j, \\textbf{v}_i \\rangle$. Hence, we find that:\n",
    "\n",
    "\\begin{align}\n",
    "    \\sum^n_{i = 1} \\sum^n_{j = 1} \\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j &= 2 \\times \\sum^n_{i = 1} \\sum^n_{j = i + 1} \\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j + \\sum^n_{i = 1} \\langle \\textbf{v}_i, \\textbf{v}_i \\rangle x_i x_i \\\\\n",
    "    \\sum^n_{i = 1} \\sum^n_{j = i + 1} \\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j &= \\frac{1}{2} (\\sum^n_{i = 1} \\sum^n_{j = 1} \\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j - \\sum^n_{i = 1} \\langle \\textbf{v}_i, \\textbf{v}_i \\rangle x_i x_i) \\\\\n",
    "    &= \\frac{1}{2}(\\sum^n_{i = 1} \\sum^n_{j = 1} \\sum^k_{f = 1} v_{i, f} v_{j, f} x_i x_j - \\sum^n_{i = 1} \\sum^k_{f = 1} v_{i, f} v_{j, f} x_i x_i) \\\\\n",
    "    &= \\frac{1}{2} \\sum^k_{f = 1} ((\\sum^n_{i = 1} v_{i, f} x_i) (\\sum^n_{j = 1} v_{j, f} x_j) - \\sum^n_{i = 1} v^2_{i, f} x^2_i) \\\\\n",
    "    &= \\frac{1}{2} \\sum^k_{f = 1} ((\\sum^n_{i = 1} v_{i, f} x_i)^2 - \\sum^n_{i = 1} v^2_{i, f} x^2_i)\n",
    "\\end{align}\n",
    "\n",
    "Using the above simplification, we see the model is linear in both $k$ and $n$. Hence the model complexity is $\\mathcal{O}(kn)$. \n",
    "\n",
    "\n",
    "### Learning the parameters\n",
    "I won't go through the details of how the parameters are learnt here, but they are learnt through gradient descent methods to minimize loss (difference between the estimate and ground truth value). Methods include Stochastic Gradient Descent (SGD), Alternating Least Square (ALS) and even Markov Chain Monte Carlo (MCMC).\n",
    "\n",
    "### Intuition of usage\n",
    "By modelling feature interaction through factorization, FM can mimic many of the existing factorization models. The key to the usage of FM is two things:\n",
    "#### - Everything is a feature. Even the userId and itemId!\n",
    "#### - It is all about using the right input data, i.e., the feature vector $\\textbf{x}$\n",
    "\n",
    "I show two examples to exemplify how existing factorization models can be translated to a FM equivalent. \n",
    "### SVDFunk/ Matrix factorization\n",
    "The original model:\n",
    "\\begin{equation}\n",
    "    r_{u, i} = b_{u, i} + p^T_u q_i\n",
    "\\end{equation}\n",
    "\n",
    "The FM equivalent:\n",
    "\\begin{equation}\n",
    "    \\hat{y}(\\textbf{x}) = w_0 + w_u + w_i + \\langle \\textbf{v}_u, \\textbf{v}_i \\rangle\n",
    "\\end{equation}\n",
    "The feature vector $\\textbf{x}$ has $n = |U \\cup I|$ components and for each component $x_j$, $x_j = 1$ if $j = i$ or $j = u$, otherwise $x_j = 0$. This means that the feature vector marks a 1 for the feature that we are currently interested in, i.e., the user $u$ and the item $i$ to be rated. \n",
    "\n",
    "$w_0$ is the overall bias. $w_u$ and $w_i$ comes from the first component $\\sum^n_{j = 1} w_j x_j$. Since all $x_j = 0$ if $j \\neq u$ nor $j \\neq i$, the summation is just left with $w_u x_u$ and $w_i x_i$ and since $x_u = x_i = 1$, we are just left with $w_u$ and $w_i$. The same idea applies to the third component $\\sum^n_{i = 1} \\sum^n_{j = i + 1} \\langle \\textbf{v}_i, \\textbf{v}_j \\rangle x_i x_j$ to get $\\langle \\textbf{v}_u, \\textbf{v}_i \\rangle$, the iteraction between $x_u$ and $x_i$. \n",
    "\n",
    "### SVD++\n",
    "The original model:\n",
    "\\begin{equation}\n",
    "    r_{u, i} = \\mu + b_u + b_i + (p_u + \\frac{1}{\\sqrt{|N(u)|}} \\sum_{j \\in N(u)} y_j)^T q_i\n",
    "\\end{equation}\n",
    "where $N(u)$ is the set of item that the user $u$ has rated. We see that we need to add additional interactions between $\\frac{1}{\\sqrt{|N(u)|}} \\sum_{j \\in N(u)} y_j$ (rated items) and $q_i$ (item to be rated). \n",
    "\n",
    "The FM equivalent:\n",
    "\\begin{equation}\n",
    "    \\hat{y}(\\textbf{x}) = w_0 + w_u + w_i + \\langle \\textbf{v}_u, \\textbf{v}_i \\rangle + \\frac{1}{\\sqrt{|N(u)|}} \\sum_{l \\in N(u)} \\langle \\textbf{v}_i, \\textbf{v}_l \\rangle + \\frac{1}{\\sqrt{|N(u)|}} \\sum_{l \\in N(u)} (w_l + \\langle \\textbf{v}_u, \\textbf{v}_l \\rangle + \\frac{1}{\\sqrt{|N(u)|}} \\sum_{l^{'} \\in N(u), l^{'} > l} \\langle v_l, v^{'}_l \\rangle)\n",
    "\\end{equation}\n",
    "\n",
    "We see that the first five terms are related to the feature interactions of the SVD++ model, i.e., the FM equivalent is mimicking the SVD++ model. The last term is an addition of the FM equivalent to model the interaction between users and items $N(u)$, $\\langle v_u, v_l \\rangle$, as well as basic effects for each item $N(u)$, $w_l$ and the interactions between pairs of items $N(u)$, $\\frac{1}{\\sqrt{|N(u)|}} \\sum_{l^{'} \\in N(u), l^{'} > l} \\langle v_l, v^{'}_l \\rangle$.\n",
    "\n",
    "Next we showcase FM prediction using the fastFM library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization using MovieLens 100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import movie lens \n",
    "movies_dir = './datasets/u.item'\n",
    "ratings_dir = './datasets/u.data'\n",
    "\n",
    "movies_col = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "movies_df = pd.read_csv(movies_dir,  sep='|', names=movies_col, usecols=range(5), encoding='latin-1')\n",
    "ratings_col = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_df = pd.read_csv(ratings_dir, index_col=None, sep='\\t', names=ratings_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of movies and ratings\n",
    "num_of_movies = len(movies_df['movie_id'].unique().tolist())\n",
    "num_of_users = len(ratings_df['user_id'].unique().tolist())\n",
    "num_of_ratings = ratings_df.shape[0]\n",
    "\n",
    "print('Num. of movies: {}\\nNum. of users: {}\\nNum. of ratings: {}'.format(num_of_movies, num_of_users, num_of_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distribution of number of ratings per movie\n",
    "movies_df['numOfRatings'] = movies_df['movie_id'].apply(lambda movie_id: ratings_df[(ratings_df['movie_id']==movie_id)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort by number of ratings\n",
    "movies_df.sort_values('numOfRatings', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index\n",
    "index = np.arange(num_of_movies)\n",
    "width = 0.35\n",
    "\n",
    "# histogram\n",
    "freq_plot = movies_df['numOfRatings'].hist(figsize=(20, 8), color='orange', bins=30)\n",
    "freq_plot.set_ylabel('Number of ratings', fontsize=25)\n",
    "freq_plot.set_xlabel('Number of movies', fontsize=25)\n",
    "freq_plot.set_title('Frequency distribution of ratings per movie', fontsize=25)\n",
    "freq_plot.set_xlim([0, 250])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful method to convert data into FM input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_single_entries_in_fm_input_format(data, itemlist):\n",
    "    '''Create the needed input (data, (row, column)) format for csc matrix for\n",
    "    the single entries in data. Each entry would take one row. This means it\n",
    "    would result in a csc matrix with dimension (|data| x |itemlist|).\n",
    "\n",
    "    :param data: single entry data\n",
    "    :type data: narray\n",
    "    :param itemlist: ordered list of possible item values\n",
    "    :type itemlist: narray\n",
    "\n",
    "    :return: data, row indexes, column indexes, shape\n",
    "    :rtype: tuple\n",
    "    '''\n",
    "    column = len(itemlist)\n",
    "    row = len(data)\n",
    "    shape = (row, column)\n",
    "\n",
    "    row_inds = np.zeros(len(data), dtype=np.int)\n",
    "    col_inds = np.zeros(len(data), dtype=np.int)\n",
    "    datalist = np.zeros(len(data), dtype=np.float)\n",
    "    for i in range(len(data)):\n",
    "        item = data[i]\n",
    "        val = 1\n",
    "        datalist[i] = val\n",
    "        # locate its position in the itemlist, throws error if item is not a\n",
    "        # possible item\n",
    "        col_ind = np.where(itemlist==item)[0]\n",
    "        # should not be duplicated items in the itemlist\n",
    "        assert len(col_ind) == 1\n",
    "        col_ind = col_ind[0]\n",
    "        row_ind = i\n",
    "\n",
    "        col_inds[i] = col_ind\n",
    "        row_inds[i] = row_ind\n",
    "\n",
    "    return datalist, row_inds, col_inds, shape\n",
    "\n",
    "\n",
    "def get_multi_entries_in_fm_input_format(data, itemlist, norm_func=None):\n",
    "    '''Create the needed input (data, (row, column)) format for csc matrix for\n",
    "    the multi entries in data. Each set of multi entries would take one row.\n",
    "    This means it would result in a csc matrix with dimension\n",
    "    (|entry sets in data| x |itemlist|).\n",
    "\n",
    "    :param data: multi entry sets in data\n",
    "    :type data: a multidimension narray\n",
    "    :param itemlist: ordered list of possible item values\n",
    "    :type itemlist: narray\n",
    "    :param norm_func: normalization function\n",
    "    :type norm_func: function that receives the size of each multi entry\n",
    "\n",
    "    :return: datalist, row indexes, column indexes, shape\n",
    "    :rtype: tuple\n",
    "    '''\n",
    "    column = len(itemlist)\n",
    "    # number of sets of entries in data\n",
    "    row = len(data)\n",
    "    shape = (row, column)\n",
    "\n",
    "    # number of data\n",
    "    num_of_data = fct.reduce(lambda x, y: x + len(y), data, 0)\n",
    "    row_inds = np.zeros(num_of_data, dtype=np.int)\n",
    "    col_inds = np.zeros(num_of_data, dtype=np.int)\n",
    "    datalist = np.zeros(num_of_data, dtype=np.float)\n",
    "    cnt = 0\n",
    "    for i in range(len(data)):\n",
    "        multi_entry = data[i]\n",
    "\n",
    "        if norm_func != None:\n",
    "            # function that receives the size of the multi_entry to decide how to normalize it\n",
    "            val = norm_func(len(multi_entry))\n",
    "        else:\n",
    "            # default binary value assignment\n",
    "            val = 1 if len(multi_entry) > 0 else 0\n",
    "\n",
    "        # for each entry in multi_entry, locate its position in the itemlist,\n",
    "        # throws error if item is not a possible item\n",
    "        # all the entries stay at the same row\n",
    "        row_ind = i\n",
    "        for item in multi_entry:\n",
    "            col_ind = np.where(itemlist==item)[0]\n",
    "            assert len(col_ind) == 1\n",
    "            col_ind = col_ind[0]\n",
    "            \n",
    "            datalist[cnt] = val\n",
    "            col_inds[cnt] = col_ind\n",
    "            row_inds[cnt] = row_ind\n",
    "            \n",
    "            # update count\n",
    "            cnt += 1\n",
    "\n",
    "    return datalist, row_inds, col_inds, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the movielens dataset into FM input format\n",
    "movielist = movies_df.sort_values('movie_id')['movie_id'].values\n",
    "userlist = ratings_df.sort_values('user_id')['user_id'].unique()\n",
    "\n",
    "# user who did ratings\n",
    "user_data = ratings_df['user_id'].values\n",
    "# movies rated\n",
    "movie_data = ratings_df['movie_id'].values\n",
    "# target vector: ratings\n",
    "rating_data = ratings_df['rating'].values\n",
    "\n",
    "# convert to FM input format\n",
    "user_datalist, user_row_inds, user_col_inds, user_shape = get_single_entries_in_fm_input_format(data=user_data, \n",
    "                                                                                                itemlist=userlist)\n",
    "movie_datalist, movie_row_inds, movie_col_inds, movie_shape = get_single_entries_in_fm_input_format(data=movie_data,\n",
    "                                                                                                   itemlist=movielist)\n",
    "\n",
    "# concat the two columns by shifting column indexes of columns related to movies\n",
    "# shift by the number of columns in user columns\n",
    "shift_by = len(userlist)\n",
    "movie_col_inds += shift_by\n",
    "# concat them\n",
    "datalist = np.append(user_datalist, movie_datalist)\n",
    "row_inds = np.append(user_row_inds, movie_row_inds)\n",
    "col_inds = np.append(user_col_inds, movie_col_inds)\n",
    "# make sure both feature set have the same number of rows\n",
    "print('User feature set shape: {}\\nMovie feature set shape: {}'.format(user_shape, movie_shape))\n",
    "assert user_shape[0] == movie_shape[0]\n",
    "shape = (user_shape[0], user_shape[1] + movie_shape[1])\n",
    "print('Dimension of FM input: {}'.format(shape))\n",
    "\n",
    "X = csc_matrix((datalist, (row_inds, col_inds)), shape=shape)\n",
    "y = rating_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change rank = 10, 50, 100, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=10, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "y_pred = fm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_als = mean_squared_error(y_test, y_pred)\n",
    "print('Mean squared error under ALS: {}'.format(error_als))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change rank = 10, 50, 100, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fm_sgd = sgd.FMRegression(n_iter=10000000, init_stdev=0.01, rank=100, random_state=123, \n",
    "                              l2_reg_w=0.1, l2_reg_V=0.5, step_size=0.01)\n",
    "fm_sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = fm_sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_sgd = mean_squared_error(y_test, y_pred_sgd)\n",
    "print('Mean squared error under SGD: {}'.format(error_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = 123\n",
    "rank = 8\n",
    "# step size is the number of iterations to continue using the current coefficients (number of samples without taking a new step)\n",
    "step_size = 10\n",
    "\n",
    "fm_mcmc = mcmc.FMRegression(n_iter=0, init_stdev=0.1, rank=rank, random_state=seed)\n",
    "# initialize the model and hyperparameters\n",
    "fm_mcmc.fit_predict(X_train=X_train, y_train=y_train, X_test=X_test)\n",
    "\n",
    "n_iter = 100\n",
    "mse_test = np.zeros(n_iter - 1)\n",
    "hyper_param = np.zeros((n_iter - 1, 3 + 2 * rank), dtype=np.float)\n",
    "for nr, i in enumerate(range(1, n_iter)):\n",
    "    fm_mcmc.random_state = i * seed\n",
    "    y_pred = fm_mcmc.fit_predict(X_train, y_train, X_test, n_more_iter=step_size)\n",
    "    mse_test[i - 1] = mean_squared_error(y_pred, y_test)\n",
    "    hyper_param[nr,:] = fm_mcmc.hyper_param_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = np.arange(1, n_iter)\n",
    "x = values * step_size\n",
    "burn_in = 50\n",
    "x = x[burn_in:]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, figsize=(20, 8))\n",
    "\n",
    "axes[0, 0].plot(x, mse_test[burn_in:], label='test rmse', color=\"r\")\n",
    "axes[0, 0].legend(fontsize=15)\n",
    "axes[0, 0].tick_params(labelsize=15)\n",
    "axes[0, 1].plot(x, hyper_param[burn_in:,0], label='alpha', color=\"b\")\n",
    "axes[0, 1].legend(fontsize=15)\n",
    "axes[0, 1].tick_params(labelsize=15)\n",
    "axes[1, 0].plot(x, hyper_param[burn_in:,1], label='lambda_w', color=\"g\")\n",
    "axes[1, 0].legend(fontsize=15)\n",
    "axes[1, 0].tick_params(labelsize=15)\n",
    "axes[1, 1].plot(x, hyper_param[burn_in:,3], label='mu_w', color=\"g\")\n",
    "axes[1, 1].legend(fontsize=15)\n",
    "axes[1, 1].tick_params(labelsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
