# -*- coding: utf-8 -*-
"""hyperparameter_tuning_optuna.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M_QnI80IcnkRV4e--m2nT4GQMbhrTvmn

# Hyperparameter Tuning

Optuna

## I. Preparacion

### Librerias
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install imblearn joblib ptitprince shap --quiet unidecode

from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, precision_recall_curve, roc_auc_score
from sklearn.model_selection import train_test_split
from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier, RUSBoostClassifier, EasyEnsembleClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import precision_recall_curve, auc, roc_curve, roc_auc_score

from unidecode import unidecode
import string

import joblib

from dateutil.relativedelta import relativedelta
from pyspark.sql import SparkSession
from matplotlib.pyplot import figure
from pyspark.sql.functions import *
from pyspark.sql.window import *
from pyspark.sql.types import *
from matplotlib import interactive
import plotly.figure_factory as ff
import pyspark.pandas as ps
import matplotlib.pyplot as plt
import plotly.express as px
import builtins as py_builtin
import seaborn as sns 
import joblib
import pandas as pd
import pyspark.pandas as ps
import numpy as np
import datetime as dt
import time
import pytz
import re
import random
import warnings
from imblearn.over_sampling import SMOTE
warnings.simplefilter('ignore')

"""### Fechas"""

#Parámetro de mes de ejecución
#La construcción de los datos se realiza con un mes de diferencia respecto al periodo actual

today = dt.date.today()
today_file = dt.datetime.now(pytz.timezone('America/Santiago')).strftime('%Y%m%d')
today_path = dt.datetime.now(pytz.timezone('America/Santiago')).strftime('%Y/%m/%d')

first = today.replace(day=1)
lastMonth = first - dt.timedelta(days=1)
penMonth  = first - dt.timedelta(days=32)
lastpenMonth  = first - dt.timedelta(days=64)
lastyear = first - dt.timedelta(days=365)

lastPeriod = lastMonth.strftime("%Y%m")
penPeriod  = penMonth.strftime("%Y%m")
lastpenPeriod  = lastpenMonth.strftime("%Y%m")
actualPeriod = today.strftime("%Y%m")
lastyearPeriod = lastyear.strftime("%Y%m")

print(actualPeriod,lastPeriod,penPeriod,lastpenPeriod, lastyearPeriod,today_path, today_file)

"""### Paths"""



"""### Functions"""



"""## II. Master

### Imputations
"""



"""### Registro único por empresa"""



"""### Consolidado"""



"""## III. Transformations"""

useless = []
to_bool = []
bools = []
nums = []

a = (to_bool + bools + nums + useless)  
a.sort()

b = master_desa_train.columns.tolist() 
b.sort()

print(a==b)

# temp = []
# for i in b:
#   if i not in a:
#     temp.append(i)
# print(temp)

"""## V. Data preparation"""



"""## VI. Models

## Hyperparameter Tuning
"""

!pip install optuna --quiet

from sklearn.model_selection import cross_val_score
from sklearn.inspection import permutation_importance
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import statsmodels.api as sm

import optuna

"""### ROC-AUC"""

def objective_brfc(trial):
  
  x, y = X_train, y_train
  
  max_depth = trial.suggest_int("brfc_max_depth", 2, 30)
  n_estimators = trial.suggest_int("brfc_n_estimators", 100, 200)
  max_samples = trial.suggest_float("brfc_max_samples", 0.2, 1)
  
  brfc_model = BalancedRandomForestClassifier(
      max_samples = max_samples,
      n_estimators = n_estimators,
      max_depth = max_depth,
      random_state = 42)
  
  score = cross_val_score(brfc_model, x, y, scoring='roc_auc', cv=10).mean()
  return score

"""#### Grupo 1"""

study_brfc = optuna.create_study(study_name = 'BalancedRandomForestClassifier Hyperparameter Optimization | G1 | auc',direction = "maximize")
study_brfc.optimize(objective_brfc, n_trials = 20)
trial = study_brfc.best_trial
print("Best Score BalancedRandomForestClassifier: ", trial.value)
print("Best Params BalancedRandomForestClassifier: ")
for key, value in trial.params.items():
    print("  {}: {}".format(key, value))

# brfc_max_depth: 30
#   brfc_n_estimators: 163
#   brfc_max_samples: 0.7045364142880505

optuna.visualization.plot_param_importances(study_brfc)

"""### F1-Score"""

def objective_f1(trial):
  
  x, y = X_train, y_train
  
  max_depth = trial.suggest_int("brfc_max_depth", 2, 30)
  n_estimators = trial.suggest_int("brfc_n_estimators", 100, 200)
  max_samples = trial.suggest_float("brfc_max_samples", 0.2, 1)
  
  brfc_model = BalancedRandomForestClassifier(
      max_samples = max_samples,
      n_estimators = n_estimators,
      max_depth = max_depth,
      random_state = 42)
  
  score = cross_val_score(brfc_model, x, y, scoring='f1', cv=10).mean()
  return score

"""#### Grupo 1"""

study_f1 = optuna.create_study(study_name = 'BalancedRandomForestClassifier Hyperparameter Optimization | G1 | f1-score',direction = "maximize")
study_f1.optimize(objective_f1, n_trials = 20)
trial_f1 = study_f1.best_trial
print("Best Score BalancedRandomForestClassifier: ", trial_f1.value)
print("Best Params BalancedRandomForestClassifier: ")
for key, value in trial_f1.params.items():
    print("  {}: {}".format(key, value))

"""### Recall"""

def objective_recall(trial):
  
  x, y = X_train, y_train
  
  max_depth = trial.suggest_int("brfc_max_depth", 2, 30)
  n_estimators = trial.suggest_int("brfc_n_estimators", 100, 200)
  max_samples = trial.suggest_float("brfc_max_samples", 0.2, 1)
  
  brfc_model = BalancedRandomForestClassifier(
      max_samples = max_samples,
      n_estimators = n_estimators,
      max_depth = max_depth,
      random_state = 42)
  
  score = cross_val_score(brfc_model, x, y, scoring='recall', cv=10).mean()
  return score

"""#### Grupo 1"""

study_recall = optuna.create_study(study_name = 'BalancedRandomForestClassifier Hyperparameter Optimization | G1 | recall',direction = "maximize")
study_recall.optimize(objective_recall, n_trials = 10)
trial_recall = study_recall.best_trial
print("Best Score BalancedRandomForestClassifier: ", trial_recall.value)
print("Best Params BalancedRandomForestClassifier: ")
for key, value in trial_recall.params.items():
    print("  {}: {}".format(key, value))

"""### Precision"""

def objective_precision(trial):
  
  x, y = X_train, y_train
  
  max_depth = trial.suggest_int("brfc_max_depth", 2, 30)
  n_estimators = trial.suggest_int("brfc_n_estimators", 100, 200)
  max_samples = trial.suggest_float("brfc_max_samples", 0.2, 1)
  
  brfc_model = BalancedRandomForestClassifier(
      max_samples = max_samples,
      n_estimators = n_estimators,
      max_depth = max_depth,
      random_state = 42)
  
  score = cross_val_score(brfc_model, x, y, scoring='precision', cv=10).mean()
  return score

"""#### Grupo 1"""

study_precision = optuna.create_study(study_name = 'BalancedRandomForestClassifier Hyperparameter Optimization | G1 | precision',direction = "maximize")
study_precision.optimize(objective_precision, n_trials = 20)
trial_precision = study_precision.best_trial
print("Best Score BalancedRandomForestClassifier: ", trial_precision.value)
print("Best Params BalancedRandomForestClassifier: ")
for key, value in trial_precision.params.items():
    print("  {}: {}".format(key, value))

'''
Best Score BalancedRandomForestClassifier:  0.1556900277465459
Best Params BalancedRandomForestClassifier: 
  brfc_max_depth: 13
  brfc_n_estimators: 167
  brfc_max_samples: 0.34869635507048075
'''

optuna.visualization.plot_param_importances(study_precision)
